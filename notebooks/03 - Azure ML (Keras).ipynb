{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploying a Model as a Web Service\n",
    "\n",
    "> **Important**: This notebook assumes that you have previously used the **02 - Image Classification (Keras).ipynb** notebook to save a Keras-based shape classification model.\n",
    "\n",
    "It's no good being able to create an accurate model if you can't deploy it for use in an application or service. In this notebook, we'll explore the *Azure Machine Learning Service* and the associated *Azure Machine Learning SDK*; which together enable you to train, deploy, and manage machine learning models at scale.\n",
    "\n",
    "To use Azure Machine Learning, you're going to need an Azure subscription. If you don't already have one, you can sign up for a free trial at https://azure.microsoft.com/Account/Free.\n",
    "\n",
    "*Note: Azure Machine Learning provides a whole range of functionality to help you through the entire lifecycle of model development, training, evaluation, deployment, and management. We're going to focus on using it to deploy a trained model; but you can use it to do much, much more!*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Brief Introduction to Containers\n",
    "When you access a web site or a software service across the internet, you're probably dimly aware that somewhere, the code for the service is hosted on a *server*. We tend to think of servers as being physical computers, but in recent years there's been a growth in *virtualization* technologies so that a computer can be virtualized in software, and multiple *virtual machines* can be hosted on a single physical server.\n",
    "\n",
    "Virtual machines (VMs) are useful - in fact, the Azure Data Science Virtual Machine (DSVM) is a good example of a VM that enables you to provision a computer that contains the operating system (OS) and all the software applications you need to work with data and build machine learning models, and then you can delete the VM when you're finished with it so that you only pay for what you use - very cool!\n",
    "\n",
    "However, it seems wasteful to provision a complete virtual machine, including the full OS and applications, just to host a simple software service - especially if you need to support multiple services, each one consuming its own VM. *Containers* are an evolutionary step beyond VMs. They contain only the OS components that are required for the specific software service they need to host. This makes them very small compared to full VMs, which in turn means that they're portable, and quick to deploy and start up.\n",
    "\n",
    "Containers themselves are hosted in a container environment that provides all the common services and OS functionality they require. During development, this environment is often a locally installed system called *Docker*. When hosting a service in the cloud however, you can use container services such as *Azure Container Instances* (ACI), which is useful for lightweight hosting and testing of containerized services; or *Azure Kubernetes Services*, which provides a scalable and highly-available environment for managing clusters of containers, based on the industry standard *Kubernetes* container hosting platform.\n",
    "\n",
    "In the rest of this notebook, we'll examine how you can use Azure Machine Learning Services to prepare a container image for your machine learning model, and deploy your model as a containerized web service that can be consumed by other applications that connect to it over an HTTP REST endpoint."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use a classification model locally\n",
    "Let's start by verifying that the classification model you created previously works locally. First install the libraries you need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "! {sys.executable} -m pip install --upgrade keras\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "from keras import backend as K\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"Ready to inference from a model using Keras %s\" % keras.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we'll create a function to generate new images, and a function to classify an image using a specified classification model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create a random image (of a square, circle, or triangle)\n",
    "def create_image (size, shape):\n",
    "    from random import randint\n",
    "    import numpy as np\n",
    "    from PIL import Image, ImageDraw\n",
    "    \n",
    "    xy1 = randint(10,40)\n",
    "    xy2 = randint(60,100)\n",
    "    col = (randint(0,200), randint(0,200), randint(0,200))\n",
    "\n",
    "    img = Image.new(\"RGB\", size, (255, 255, 255))\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    \n",
    "    if shape == 'circle':\n",
    "        draw.ellipse([(xy1,xy1), (xy2,xy2)], fill=col)\n",
    "    elif shape == 'square':\n",
    "        draw.rectangle([(xy1,xy1), (xy2,xy2)], fill=col)\n",
    "    else: # triangle\n",
    "        draw.polygon([(xy1,xy1), (xy2,xy2), (xy2,xy1)], fill=col)\n",
    "    del draw\n",
    "    \n",
    "    return np.array(img)\n",
    "\n",
    "def predict_image(classifier, image_array):\n",
    "    import numpy as np\n",
    "    \n",
    "    # We need to format the input to match the training data\n",
    "    # The generator loaded the values as floating point numbers\n",
    "    # and normalized the pixel values, so...\n",
    "    imgfeatures = image_array.astype('float32')\n",
    "    imgfeatures /= 255\n",
    "    \n",
    "    # These are the classes our model can predict\n",
    "    classnames = ['circle', 'square', 'triangle']\n",
    "    \n",
    "    # Predict the class of each input image\n",
    "    predictions = classifier.predict(imgfeatures)\n",
    "    \n",
    "    predicted_classes = []\n",
    "    for prediction in predictions:\n",
    "        # The prediction for each image is the probability for each class, e.g. [0.8, 0.1, 0.2]\n",
    "        # So get the index of the highest probability\n",
    "        class_idx = np.argmax(prediction)\n",
    "        # And append the corresponding class name to the results\n",
    "        predicted_classes.append(classnames[int(class_idx)])\n",
    "    # Return the predictions\n",
    "    return predicted_classes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you're ready to try to classify new images using the model you created in the previous challenge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "from random import randint\n",
    "\n",
    "# Create a random test image\n",
    "classnames = ['circle', 'square', 'triangle']\n",
    "img_size = (128,128)\n",
    "img = create_image (img_size, classnames[randint(0, len(classnames)-1)])\n",
    "plt.imshow(img)\n",
    "\n",
    "# Load the model you saved in the previous challenge\n",
    "modelFileName = 'shape-classifier.h5'\n",
    "model = load_model(modelFileName) # loads the saved model\n",
    "\n",
    "# Create an array of (1) images to match the expected input format\n",
    "img_array = img.reshape(1, img.shape[0], img.shape[1], img.shape[2])\n",
    "\n",
    "# get the predicted clases\n",
    "predicted_classes = predict_image(model, img_array)\n",
    "\n",
    "# Display the prediction for the first image (we only submitted one!)\n",
    "print(predicted_classes[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks as though we have a working model. Now we're ready to use Azure Machine Learning to deploy it as a web service."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an Azure Machine Learning workspace\n",
    "\n",
    "To use Azure Machine Learning, you'll need to create a workspace in your Azure subscription.\n",
    "\n",
    "Your Azure subscription is identified by a subscription ID. To find this:\n",
    "1. Sign into the Azure portal at https://portal.azure.com.\n",
    "2. On the menu tab on the left, click &#128273; **Subscriptions**.\n",
    "3. View the list of your subscriptions and copy the ID for the subscription you want to use.\n",
    "4. Paste the subscription ID into the code below, and then run the cell to set the variable - you will use it later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace YOUR_SUBSCRIPTION_ID in the following variable assignment:\n",
    "SUBSCRIPTION_ID = 'YOUR_SUBSCRIPTION_ID'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To deploy the model file as a web service, we'll use the Azure Machine Learning SDK.\n",
    "\n",
    "> Note: the Azure Machine Learning SDK is installed by default in Azure Notebooks and the Azure Data Science Virtual Machine, but you may want to ensure that it's upgraded to the latest version. If you're using your own Python environment, you'll need to install it using the instructions in the [Azure Machine Learning documentation](https://docs.microsoft.com/en-us/python/api/overview/azure/ml/install?view=azure-ml-py)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "! {sys.executable} -m pip install azureml-sdk --upgrade\n",
    "\n",
    "import azureml.core\n",
    "print(azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To manage the deployment, we need an Azure ML workspace. Create one in your Azure subscription by running the following cell. You'll be prompted to authenticate by entering a code at a given URL, so just click the link that's displayed and enter the specified code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Workspace\n",
    "ws = Workspace.create(name='my_aml_workspace', # or another name of your choosing\n",
    "                      subscription_id=SUBSCRIPTION_ID,\n",
    "                      resource_group='aml_resources', # or another name of your choosing\n",
    "                      create_resource_group=True,\n",
    "                      location='eastus2' # or other supported Azure region\n",
    "                     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have a workspace, you can save the configuration so you can reconnect to it later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Workspace\n",
    "\n",
    "# Save the workspace config\n",
    "ws.write_config()\n",
    "\n",
    "# Reconnect to the workspace (if you're not already signed in, you'll be prompted to authenticate with a code as before)\n",
    "ws = Workspace.from_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Register the model in Azure ML\n",
    "\n",
    "You've created a model and saved it locally. Now you can register this model in your Azure ML workspace, which will enable you to manage and deploy it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.model import Model\n",
    "\n",
    "model = Model.register(model_path = \"shape-classifier.h5\",\n",
    "                       model_name = \"shape-classifier-keras\",\n",
    "                       tags = {'area': \"shapes\", 'type': \"classifier\"},\n",
    "                       description = \"Keras shape classifier\",\n",
    "                       workspace = ws)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a *scoring* file\n",
    "Your web service will need some Python code to load the input data, get the model, and generate and return a prediction. We'll save this code in a *scoring* file that will be deployed to the web service:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile score_keras.py\n",
    "# scoring script used by service to load model and generate prediction\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "from keras.models import load_model\n",
    "from azureml.core.model import Model\n",
    "\n",
    "# Called when the service is loaded\n",
    "def init():\n",
    "    global model\n",
    "    # Get the path to the registered model file and load it\n",
    "    model_path = Model.get_model_path('shape-classifier-keras')\n",
    "    model = load_model(model_path)\n",
    "\n",
    "# Called when a request is received\n",
    "def run(raw_data):\n",
    "    # Get the input data - the image(s) to be classified.\n",
    "    data = np.array(json.loads(raw_data)['data'])\n",
    "    \n",
    "    # Pre-process the images\n",
    "    imgfeatures = data.astype('float32')\n",
    "    imgfeatures /= 255\n",
    "\n",
    "    # Get a prediction from the model\n",
    "    predictions = model.predict(imgfeatures)\n",
    "    # get thge classname for the highest probability prediction for each input\n",
    "    classnames = ['circle', 'square', 'triangle']\n",
    "    predicted_classes = []\n",
    "    for prediction in predictions:\n",
    "        class_idx = np.argmax(prediction)\n",
    "        predicted_classes.append(classnames[int(class_idx)])\n",
    "    # Return the predictions as a JSON\n",
    "    return json.dumps(predicted_classes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an *environment* file\n",
    "The web service will be hosted in a container, and the container will need to install any required Python dependencies when it gets initialized. In this case, our scoring code requires **scikit-learn**, so we'll create a .yml file that tells the container host to install this into the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.conda_dependencies import CondaDependencies \n",
    "\n",
    "myenv = CondaDependencies()\n",
    "myenv.add_conda_package(\"keras\")\n",
    "\n",
    "env_file = \"env_keras.yml\"\n",
    "\n",
    "with open(env_file,\"w\") as f:\n",
    "    f.write(myenv.serialize_to_string())\n",
    "print(\"Saved dependency info in\", env_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy the web service \n",
    "Now we're ready to deploy. We'll deploy the container a service named **keras-shape-classifier**.\n",
    "The deployment process includes the following steps:\n",
    "1. Define an *inference configuration*, which includes the scoring and environment files required to load and use the model.\n",
    "2. Define a *deployment configuration* that defines the execution environment in which the service will be hosted. In this case, an Azure Container Instance.\n",
    "3. Deploy the web service.\n",
    "4. Verify the status of the deployed service.\n",
    "\n",
    "This will take some time. When deployment has completed successfully, you'll see a status of **Healthy**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.webservice import AciWebservice\n",
    "from azureml.core.model import InferenceConfig\n",
    "\n",
    "inference_config = InferenceConfig(runtime= \"python\", \n",
    "                                   entry_script=\"score_keras.py\",\n",
    "                                   conda_file=\"env_keras.yml\")\n",
    "\n",
    "deployment_config = AciWebservice.deploy_configuration(cpu_cores = 1, memory_gb = 1)\n",
    "\n",
    "service_name = \"keras-shape-classifier\"\n",
    "\n",
    "service = Model.deploy(ws, service_name, [model], inference_config, deployment_config)\n",
    "\n",
    "service.wait_for_deployment(True)\n",
    "print(service.state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the web service\n",
    "With the service deployed, now we can test it by using it to predict the shape of a new image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from random import randint\n",
    "\n",
    "# Create a random test image\n",
    "img = create_image (img_size, classnames[randint(0, len(classnames)-1)])\n",
    "plt.imshow(img)\n",
    "\n",
    "# Modify the image data to create an array of 1 image, matching the format of the training features\n",
    "input_array = img.reshape(1, img.shape[0], img.shape[1], img.shape[2])\n",
    "\n",
    "# Convert the array to JSON format\n",
    "input_json = json.dumps({\"data\": input_array.tolist()})\n",
    "\n",
    "# Call the web service, passing the input data (the web service will also accept the data in binary format)\n",
    "predictions = service.run(input_data = input_json)\n",
    "\n",
    "# Get the predicted class - it'll be the first (and only) one.\n",
    "classname = json.loads(predictions)[0]\n",
    "print('The image is a', classname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also send a batch of images to the service, and get back a prediction for each one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from random import randint\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Create three random test images\n",
    "fig = plt.figure(figsize=(8, 8))\n",
    "images = []\n",
    "i = 0\n",
    "while(i < 3):  \n",
    "    # Create a new image\n",
    "    img = create_image(img_size, classnames[randint(0, len(classnames)-1)])\n",
    "    # Plot the image\n",
    "    a=fig.add_subplot(1,3,i + 1)\n",
    "    imgplot = plt.imshow(img)\n",
    "    # Add the image to an array to be submitted as a batch\n",
    "    images.append(img.tolist())\n",
    "    i += 1\n",
    "\n",
    "# Convert the array to JSON format\n",
    "input_json = json.dumps({\"data\": images})\n",
    "\n",
    "# Call the web service, passing the input data\n",
    "predictions = service.run(input_data = input_json)\n",
    "\n",
    "# Get the predicted classes\n",
    "print(json.loads(predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the Web Service from Other Applications\n",
    "The code above uses the Azure ML SDK to connect to the containerized web service and use it to generate predictions from your image classification model. In production, the model is likely to be consumed by business applications that make HTTP requests to the web service.\n",
    "\n",
    "Let's determine the URL to which these applications must submit their requests:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint = service.scoring_uri\n",
    "print(endpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we know the endpoint URI, an application can simply make an HTTP request, sending the image data in JSON (or binary) format, and receive back the predicted class(es)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import requests\n",
    "import json\n",
    "from random import randint\n",
    "\n",
    "# Create a random test image\n",
    "img = create_image (img_size, classnames[randint(0, len(classnames)-1)])\n",
    "plt.imshow(img)\n",
    "\n",
    "# Create an array of (1) images to match the expected input format\n",
    "image_array = img.reshape(1, img.shape[0], img.shape[1], img.shape[2])\n",
    "\n",
    "# Convert the array to a serializable list in a JSON document\n",
    "input_json = json.dumps({\"data\": image_array.tolist()})\n",
    "\n",
    "# Set the content type\n",
    "headers = { 'Content-Type':'application/json' }\n",
    "\n",
    "predictions = requests.post(endpoint, input_json, headers = headers)\n",
    "print(json.loads(predictions.content))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deleting the Service\n",
    "\n",
    "When we're finished with the service, we can delete it to avoid incurring charges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "service.delete()\n",
    "print(\"Service deleted.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And if you're finished with the workspace, you can delete that too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rg = ws.resource_group\n",
    "ws.delete()\n",
    "print(\"Workspace deleted. You should delete the '%s' resource group in your Azure subscription.\" % rg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learn more\n",
    "Take a look at the Azure Machine Learning documentation at https://docs.microsoft.com/en-us/azure/machine-learning/service/."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
